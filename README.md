# ğŸ§  AI SE Assistant â€” Python Data Pipeline Project

A small, modular, and testable Sales Engineering Data Pipeline that loads opportunities from CSV, 
validates fields, performs analytics (win rate, proposal opportunities, pipeline by owner, top deals), and 
writes results to JSON.

## ğŸ”¬ This project demonstrates:

- Clean Python project structure
- Config-driven pipelines
- Data validation
- Modular functions
- Logging 
- Automated testing with pytest 
- Command-line execution
- Realistic SE-style data analysis

## ğŸš€ Features

- Config-driven execution using YAML 
- Safe CSV loading with validation 
- Analytics functions:
  - Proposal opportunities 
  - Win rate calculation 
  - Pipeline by owner 
  - Top N deals 
- JSON output writer 
- CLI support: choose input CSV, N for top deals, validate-only mode 
- pytest test suite 
- Clean, professional folder structure

## ğŸ“‚ Project Structure
```plaintext
ai-se-assistant/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ opportunities.csv
â”‚   â”œâ”€â”€ opportunities_sorted.csv
â”‚   â””â”€â”€ opportunities_proposals.csv
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ pipeline_results.json
â”‚   â””â”€â”€ pipeline.log
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_pipeline.py
â”‚   â”œâ”€â”€ opportunity_functions.py
â”‚   â”œâ”€â”€ opportunity_summary.py
â”‚   â”œâ”€â”€ opportunity_transform.py
â”‚   â”œâ”€â”€ test_environment.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ venv/              â† ignored by git
â”œâ”€â”€ .env               â† ignored by git
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ Installation

1. Clone or download the repository
```
git clone https://github.com/YOUR_USERNAME/ai-se-assistant.git
cd ai-se-assistant
```

2. Create a virtual environment
```
python3 -m venv venv
source venv/bin/activate     # on macOS
```
3. Install dependencies
```
pip install -r requirements.txt
```

## â–¶ï¸ Running the Pipeline

Basic run
```
python scripts/data_pipeline.py
```

Using a different input file
```
python scripts/data_pipeline.py --input data/opportunities.csv
```

Override top N deals
```
python scripts/data_pipeline.py --top 5
```
Validation-only mode
```
python scripts/data_pipeline.py --validate-only
```

## ğŸ“„ Configuration (config/config.yaml)
```yaml
input_csv: "data/opportunities.csv"
top_n: 3
output_dir: "outputs"
log_file: "pipeline.log"
required_columns:
  - Name
  - Owner
  - Stage
  - Amount
```
## ğŸ§ª Running Tests
```
pytest
```

## ğŸ“Š Example Output (pipeline_results.json)
```json
{
  "proposal_opportunities": [
      { "Name": "ABC Deal", "Owner": "Marc", "Stage": "Proposal", "Amount": 50000 }
  ],
  "win_rate": 0.25,
  "pipeline_by_owner": {
    "Marc": 125000,
    "Sarah": 90000
  },
  "top_3_deals": [
    { "Name": "BigCo Expansion", "Amount": 120000 },
    { "Name": "TechCorp Renewal", "Amount": 90000 },
    { "Name": "Startup Pilot", "Amount": 75000 }
  ],
  "input_file": "data/opportunities.csv",
  "top_n": 3
}
```

## ğŸ›£ï¸ Roadmap (Next Steps)

- Add chart generation via matplotlib 
- Add API endpoint (FastAPI)
- Add database support (SQLite or PostgreSQL)
- Add more automated tests 
- Add real-world Salesforce sample exports 
- Build a Streamlit UI 
- Add CI/CD (GitHub Actions)

## ğŸ‘¤ Author

**Marc Sardello**  
Principal Solutions Engineer / Technical Pre-Sales Professional  

With a career spanning finance systems, enterprise planning, BI, big data, data preparation, analytics, and Quote-to-Cash architecture, I bring deep experience in understanding complex systems and translating them into practical, scalable technical solutions.  

Past roles include work across IBM (TM1 & Cognos), Microsoft (Advanced Analytics & Revolution R), Qlik, Datawatch, Unifi Software, Trifacta, and Salesforce Revenue Cloud.  

This project is part of my ongoing focus on sharpening Python, data engineering, and AI-enabled solution design skills to support the growth and evolution of my career. 
